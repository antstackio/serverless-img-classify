{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FE7KNzPPVrVV"
   },
   "source": [
    "# Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zF9uvbXNVrVY"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "REAW4861moBF",
    "outputId": "fae6c0d8-63d4-4cd0-c63e-5e23345486aa"
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZZI6lNkVrVm"
   },
   "source": [
    "## Download and explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://prad-ml/data/ data --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57CcilYSG0zv"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = 'data'\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbtTDYhOHZb6",
    "outputId": "5dd5ccef-8574-4205-f1cb-d7709b9c13f6"
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "N1loMlbYHeiJ",
    "outputId": "8303abe6-a424-491f-d764-8afd93de946e"
   },
   "outputs": [],
   "source": [
    "hitman = list(data_dir.glob('Hitman/*'))\n",
    "PIL.Image.open(str(hitman[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "RQbZBOTLHiUP",
    "outputId": "acd5ca6c-6924-468c-fa10-e933f3dc9424"
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(str(hitman[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "HyQkfPGdHilw",
    "outputId": "88fe6c1a-ebbf-4d1e-bcdb-ec1790151295"
   },
   "outputs": [],
   "source": [
    "unity = list(data_dir.glob('ACUnity/*'))\n",
    "PIL.Image.open(str(unity[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 909
    },
    "id": "wtlhWJPAHivf",
    "outputId": "f1257527-76ba-460e-9a75-f7936b095c41"
   },
   "outputs": [],
   "source": [
    "PIL.Image.open(str(unity[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIjgz7_JIo_m"
   },
   "source": [
    "# Load data using a Keras utility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyDNn9MbIzfT"
   },
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anqiK_AGI086"
   },
   "source": [
    "Define some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H74l2DoDI2XD"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFBhRrrEI49z"
   },
   "source": [
    "It's good practice to use a validation split when developing your model. Let's use 80% of the images for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIR0kRZiI_AT",
    "outputId": "b45d9d32-c4e0-47af-ff6d-4c8661055503"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iscU3UoVJBXj",
    "outputId": "1d1db817-a5aa-4386-9cf6-b0dd5e945630"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLQULyAvJC3X"
   },
   "source": [
    "You can find the class names in the `class_names` attribute on these datasets. These correspond to the directory names in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZHAxkHX5JD3k",
    "outputId": "ca15551d-791e-497e-81b7-ed7c2f2642c8"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uoVvxSLJW9m"
   },
   "source": [
    "## Visualize the data\n",
    "\n",
    "Here are the first nine images from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "wBmEA9c0JYes",
    "outputId": "2ec30e04-5a85-4ef7-d5e3-8c3c9362327b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(8):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M6BXtXFJdW0"
   },
   "source": [
    "You will train a model using these datasets by passing them to `Model.fit` in a moment. If you like, you can also manually iterate over the dataset and retrieve batches of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-MfMoenJi8s",
    "outputId": "487b80c4-99a1-4eb3-aeac-17ebf7fdc213"
   },
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wj4FrKxxJkoW"
   },
   "source": [
    "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.\n",
    "\n",
    "You can call `.numpy()` on the `image_batch` and `labels_batch` tensors to convert them to a `numpy.ndarray`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Dr0at41KcAU"
   },
   "source": [
    "## Configure the dataset for performance\n",
    "\n",
    "Let's make sure to use buffered prefetching so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data:\n",
    "\n",
    "- `Dataset.cache` keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
    "- `Dataset.prefetch` overlaps data preprocessing and model execution while training.\n",
    "\n",
    "Interested readers can learn more about both methods, as well as how to cache data to disk in the *Prefetching* section of the [Better performance with the tf.data API](../../guide/data_performance.ipynb) guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOjJSm7DKoZA"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GUnmPF4JvEf"
   },
   "source": [
    "## Standardize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e56VXHMWJxYT"
   },
   "source": [
    "The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network; in general you should seek to make your input values small.\n",
    "\n",
    "Here, you will standardize values to be in the `[0, 1]` range by using `tf.keras.layers.Rescaling`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEYxo2CTJvY9"
   },
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl4RmanbJ4g0"
   },
   "source": [
    "There are two ways to use this layer. You can apply it to the dataset by calling `Dataset.map`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9o9ESaJJ502",
    "outputId": "82422b86-d4b7-4424-ea71-b1909e0a688d"
   },
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWEOmRSBJ9J8"
   },
   "source": [
    "Or, you can include the layer inside your model definition, which can simplify deployment. Let's use the second approach here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsRk1xCwKZR4"
   },
   "source": [
    "Note: You previously resized images using the `image_size` argument of `tf.keras.utils.image_dataset_from_directory`. If you want to include the resizing logic in your model as well, you can use the `tf.keras.layers.Resizing` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDMfYqwmM1C-"
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxYwix81M2YO"
   },
   "source": [
    "Overfitting generally occurs when there are a small number of training examples. [Data augmentation](./data_augmentation.ipynb) takes the approach of generating additional training data from your existing examples by augmenting them using random transformations that yield believable-looking images. This helps expose the model to more aspects of the data and generalize better.\n",
    "\n",
    "You will implement data augmentation using the following Keras preprocessing layers: `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation`, and `tf.keras.layers.RandomZoom`. These can be included inside your model like other layers, and run on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9J80BAbIMs21"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN4k1dK3S6eV"
   },
   "source": [
    "Let's visualize what a few augmented examples look like by applying data augmentation to the same image several times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "7Z90k539S838",
    "outputId": "9d7fbdf9-7147-4041-94fe-44c9d7e68f8a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsjXCBLYYNs5"
   },
   "source": [
    "You will use data augmentation to train a model in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeD3bXepYKXs"
   },
   "source": [
    "## Dropout\n",
    "\n",
    "Another technique to reduce overfitting is to introduce [dropout](https://developers.google.com/machine-learning/glossary#dropout_regularization) regularization to the network.\n",
    "\n",
    "When you apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
    "\n",
    "Let's create a new neural network with `tf.keras.layers.Dropout` before training it using the augmented images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Zeg8zsqXCsm"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4nEcuqgZLbi"
   },
   "source": [
    "## Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvyAINs9ZOmJ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWLkKoKjZSoC",
    "outputId": "df9cfeeb-0983-4f57-8057-28958b64f861"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWS-vvNaZDag",
    "outputId": "6a9e365f-92d1-4f4a-828f-8452cb0bac5e"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkdl8VsBbZOu"
   },
   "source": [
    "## Visualize training results\n",
    "\n",
    "After applying data augmentation and `tf.keras.layers.Dropout`, there is less overfitting than before, and training and validation accuracy are closer aligned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "dduoLfKsZVIA",
    "outputId": "06d535f6-4020-41fb-e8bf-81e990a1f2aa"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtv5VbaVb-3W"
   },
   "source": [
    "## Predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10buWpJbcCQz"
   },
   "source": [
    "Finally, let's use our model to classify an image that wasn't included in the training or validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKgMZ4bDcHf7"
   },
   "source": [
    "Note: Data augmentation and dropout layers are inactive at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmTLtmSQqzC7"
   },
   "outputs": [],
   "source": [
    "gameClass = 'SM-clf.h5'\n",
    "reloaded_model.save(gameClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BG5IgjksrM5r"
   },
   "outputs": [],
   "source": [
    "reloaded_model = tf.keras.models.load_model('/gameClass.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVtWNSpMTfCL"
   },
   "outputs": [],
   "source": [
    "class_names = ['ACUnity', 'Hitman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "dC40sRITBSsQ",
    "outputId": "64d6d15f-1d95-4db8-cdfb-11ad89645a37"
   },
   "outputs": [],
   "source": [
    "hman = \"https://i.ytimg.com/vi/W5WGkbBcRUk/maxresdefault.jpg\"\n",
    "hit = tf.keras.utils.get_file('img', origin=hman)\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    hit, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = reloaded_model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n",
    "PIL.Image.open(str(hit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp SM-clf.h5 s3://<YOUR-BUCKET-NAME>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hitman/ACU.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "102a77dd866ac612966e57b91207d27d7eb54b444a46ded57de0c8246989a891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
